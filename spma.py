# -*- coding: utf-8 -*-
"""SPMa.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nm5JV-DmKomQo8pc2jkcuOF2iqIUnD5d
"""

# Install necessary libraries
!pip install pandas matplotlib seaborn scikit-learn
from google.colab import drive
drive.mount('/content/drive')
import os
import pandas as pd

# Mapping of company names to stock codes
company_code_map = {
    'Steel Authority of India': 'SAIL',
    'Indian Oil Corporation': 'IOC',
    'Adani Enterprises': 'ADANIENT',
    'Tata Motors': 'TATAMOTORS',
    'Wipro': 'WIPRO',
    'Hindalco Industries': 'HINDALCO',
    'Tata Steel': 'TATASTEEL',
    'ICICI Bank': 'ICICIBANK',
    'Bank of Baroda': 'BANKBARODA',
    'Adani Ports': 'ADANIPORTS',
    'Bharti Airtel': 'BHARTIARTL',
    'Reliance Industries': 'RELIANCE',
    'Kotak Mahindra Bank': 'KOTAKBANK',
    'Tata Consultancy Services': 'TCS',
    'Larsen & Toubro': 'LT',
    'Maruti Suzuki': 'MARUTI',
    'HDFC Bank': 'HDFCBANK'
}

# Path to your stock data folder in Google Drive
folder_path = "/content/drive/My Drive/stock_data/"

# Dictionary to store dataframes
stock_data = {}

# Load CSV files and use stock codes as keys
for filename in os.listdir(folder_path):
    if filename.endswith(".csv"):
        company_name = filename.replace('.csv', '')  # Remove '.csv'
        stock_code = company_code_map.get(company_name)  # Get the stock code
        if stock_code:
            file_path = os.path.join(folder_path, filename)
            stock_data[stock_code] = pd.read_csv(file_path)

# Output the stock codes (keys)
print(stock_data.keys())
# 1. Split Date and Time
for company, df in stock_data.items():
    df['date'] = pd.to_datetime(df['date'])  # Convert to datetime objects
    df['Trade_Date'] = df['date'].dt.date  # Extract date
    df['Trade_Time'] = df['date'].dt.time  # Extract time

# 2. Find Common Trading Dates (Ignoring Time)
common_dates = set(stock_data['SAIL']['Trade_Date'])
for company, df in stock_data.items():
    common_dates = common_dates.intersection(set(df['Trade_Date']))
common_dates = sorted(list(common_dates), reverse=True)

# 3. Narrow Down to Last 30 Trading Days
common_dates = common_dates[:30]

# 4. Filter DataFrames
for company, df in stock_data.items():
    stock_data[company] = df[df['Trade_Date'].isin(common_dates)].reset_index(drop=True)

# 5. Optional: Drop the original 'date' column if not needed
# for company, df in stock_data.items():
#     df.drop(columns=['date'], inplace=True)
for company, df in stock_data.items():
    # Absolute difference between high and low
    df['High_Low_Diff'] = abs(df['high'] - df['low'])

    # Absolute difference between open and close
    df['Open_Close_Diff'] = abs(df['open'] - df['close'])

    # Positive or negative change (1 for positive, 0 for negative)
    df['Change_Type'] = (df['close'] - df['open']).apply(lambda x: 1 if x > 0 else 0)

    # Percentage change from the open value
    df['Pct_Change'] = ((df['close'] - df['open']) / df['open']) * 100

import os
os.makedirs("/content/drive/My Drive/stock_data/processed/")

# Save processed data to CSV
for company, df in stock_data.items():
    df.to_csv(f'/content/drive/My Drive/stock_data/processed/{company}_processed.csv', index=False)